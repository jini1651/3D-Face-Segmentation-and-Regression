{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchsummary\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# from model_utils import EncodingLayer, SphericalMaxPooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SF1 = np.random.randint(0, 3, (642, 3)), np.random.randint(-1, 642, (642, 6))\n",
    "SF2 = np.random.randint(0, 3, (162, 3)), np.random.randint(-1, 162, (162, 6))\n",
    "SF3 = np.random.randint(0, 3, (42, 3)), np.random.randint(-1, 42, (42, 6))\n",
    "SFs = [SF3, SF2, SF1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.SFCNN import get_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 16]) torch.Size([2, 16, 642])\n",
      "torch.Size([2, 32]) torch.Size([2, 32, 162])\n",
      "torch.Size([2, 64]) torch.Size([2, 64, 42])\n",
      "torch.Size([2, 128]) torch.Size([2, 128, 42])\n",
      "torch.Size([2, 480])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [24, 16, 6, 642]              48\n",
      "       BatchNorm2d-2           [24, 16, 6, 642]              32\n",
      "            Conv2d-3           [24, 16, 6, 642]             272\n",
      "       BatchNorm2d-4           [24, 16, 6, 642]              32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rmclab102/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't multiply sequence by non-int of type 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-8424f8b963bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorchsummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSFs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m642\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torchsummary/torchsummary.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[1;32m     91\u001b[0m         )\n\u001b[1;32m     92\u001b[0m         \u001b[0mtotal_params\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"nb_params\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtotal_output\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"output_shape\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"trainable\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"trainable\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mprod\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mprod\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   3050\u001b[0m     \"\"\"\n\u001b[1;32m   3051\u001b[0m     return _wrapreduction(a, np.multiply, 'prod', axis, dtype, out,\n\u001b[0;32m-> 3052\u001b[0;31m                           keepdims=keepdims, initial=initial, where=where)\n\u001b[0m\u001b[1;32m   3053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't multiply sequence by non-int of type 'list'"
     ]
    }
   ],
   "source": [
    "torchsummary.summary(get_model(40, SFs).cuda(), input_size=(1, 642), batch_size=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# from model_utils import EncodingLayer, SphericalMaxPooling\n",
    "\n",
    "def makeInputData(input_feature, SF):\n",
    "    #feature에서 근점 점 6개 인덱스 뽑아서 MLP 입력 블럭으로 만들어놔\n",
    "    #output : B x N x 6 x 2C (기준 점x6 로 늘려서 근접 점이랑 붙이삼)\n",
    "    '''\n",
    "    input : B x N x C\n",
    "    SF : N x (xyz + p1~p6)\n",
    "\n",
    "    input*6 + p1~p6 (concat) => output\n",
    "\n",
    "    output : B x N x 6 x 2C\n",
    "    '''\n",
    "    #임시로 해놓음\n",
    "    # input_feature = input_feature.numpy()\n",
    "    input_feature = torch.Tensor(input_feature)\n",
    "    # print(input_feature.shape)\n",
    "    B, N, C = input_feature.shape\n",
    "    vertices, near_idx = SF         #near_idx : Nx6\n",
    "    # features = np.reshape(input_feature, (B, N, 1, C))\n",
    "    # input_feature = input_feature.permute(0, 2, 1)\n",
    "    features = input_feature.view(B, N, 1, C)\n",
    "    # features = np.repeat(features, 6, axis=2)   #BxNx6xC\n",
    "    features = features.repeat(1, 1, 6, 1)    #BxNx6xC\n",
    "\n",
    "    # outofidx_6 = np.zeros((B, N, C)) - 1\n",
    "    outofidx_6 = torch.zeros((B, N, C)) - 1\n",
    "    # input_feature = np.concatenate((input_feature, outofidx_6), axis=1) #Bx(N+1)xC\n",
    "\n",
    "    input_feature =  torch.cat((input_feature, outofidx_6), 1)    #Bx(N+1)xC\n",
    "\n",
    "    near_features = input_feature[:, near_idx, :]   #BxNx6xC\n",
    "\n",
    "    # feature_block = np.concatenate((features, near_features), axis=-1)  #BxNx6x2C\n",
    "    feature_block = torch.cat((features, near_features), 3)  #BxNx6x2C\n",
    "\n",
    "    # feature_block = torch.Tensor(feature_block)\n",
    "\n",
    "    return feature_block    #BxNx6x2C\n",
    "\n",
    "def SphericalMaxPooling(input, in_SF, out_SF):\n",
    "    '''\n",
    "    input : B x C x N0\n",
    "    SF0 : (xyz, p01~p05 idx) - (N0 x 3), (N0 x 6)\n",
    "    SF1 : (xyz, p10~p15 idx) - (N1 x 3), (N1 x 6)\n",
    "\n",
    "    output : B x N1 x C\n",
    "\n",
    "    for SF1:\n",
    "        for SF2:\n",
    "            SF2-xyz중에 SF1이랑 같은거 찾아서 p01~p06 인덱스 input에서 d 꺼내와서 pooling\n",
    "            그 값 ouput에 추가\n",
    "    '''\n",
    "    B, C, N = input.shape\n",
    "    input = input.permute(0, 2, 1)\n",
    "\n",
    "    in_v, in_ni = in_SF\n",
    "    out_v, out_ni = out_SF\n",
    "\n",
    "    in_nvertices = in_v.shape[0]\n",
    "    out_nvertices = out_v.shape[0]\n",
    "\n",
    "    output = torch.zeros((B, out_nvertices, C))\n",
    "    \n",
    "    for i in range(out_nvertices):\n",
    "        out_xyz = out_v[i]\n",
    "        for j in range(in_nvertices):\n",
    "            if out_xyz.all() == in_v[j].all():\n",
    "                near_idx = in_ni[j]  #Bx6\n",
    "                temp = input[:, near_idx, :]   #Bx6xC\n",
    "                output[:, i, :] = torch.max(temp, 1)[0]     #BxC\n",
    "\n",
    "    input = input.permute(0, 2, 1)\n",
    "\n",
    "    return output   #BxCxN'\n",
    "\n",
    "    # # input : B x N x (xyz + d + p1~p6 + alpha)로 먼저 만드삼\n",
    "    # # alpha - pooling 기준 점인지 아닌지 (0 : x, 1 : o)\n",
    "    # # for i in range(N):\n",
    "    # #   a=0이면 pass\n",
    "    # #   a=1이면 p1~p6 d값 포함 maxpooling 하고 p1~p6 a값 0으로 변경\n",
    "    # # 그리고 a=0인 애들 다 죽이삼\n",
    "    # # output : B x N x (xyz + d)\n",
    "    # 이거 아님\n",
    "\n",
    "class SphericalMaxPooling(nn.Module):\n",
    "    def __init__(self, in_SF, out_SF):\n",
    "        super(SphericalMaxPooling, self).__init__()\n",
    "        self.in_SF = in_SF\n",
    "        self.out_SF = out_SF\n",
    "    '''\n",
    "    input : B x C x N0\n",
    "    SF0 : (xyz, p01~p05 idx) - (N0 x 3), (N0 x 6)\n",
    "    SF1 : (xyz, p10~p15 idx) - (N1 x 3), (N1 x 6)\n",
    "\n",
    "    output : B x N1 x C\n",
    "\n",
    "    for SF1:\n",
    "        for SF2:\n",
    "            SF2-xyz중에 SF1이랑 같은거 찾아서 p01~p06 인덱스 input에서 d 꺼내와서 pooling\n",
    "            그 값 ouput에 추가\n",
    "    '''\n",
    "\n",
    "    def forward(self, input):\n",
    "        B, C, N = input.shape\n",
    "        input = input.permute(0, 2, 1)\n",
    "\n",
    "        in_v, in_ni = self.in_SF\n",
    "        out_v, out_ni = self.out_SF\n",
    "\n",
    "        in_nvertices = in_v.shape[0]\n",
    "        out_nvertices = out_v.shape[0]\n",
    "\n",
    "        output = torch.zeros((B, out_nvertices, C))\n",
    "        \n",
    "        for i in range(out_nvertices):\n",
    "            out_xyz = out_v[i]\n",
    "            for j in range(in_nvertices):\n",
    "                if out_xyz.all() == in_v[j].all():\n",
    "                    near_idx = in_ni[j]  #Bx6\n",
    "                    temp = input[:, near_idx, :]   #Bx6xC\n",
    "                    output[:, i, :] = torch.max(temp, 1)[0]     #BxC\n",
    "\n",
    "        output = output.permute(0, 2, 1)\n",
    "\n",
    "        return output   #BxCxN'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# from models.SFCNN_utils import EncodingLayer, SphericalMaxPooling\n",
    "# from models.SFCNN_utils import EncodingLayer\n",
    "\n",
    "\n",
    "class get_model(nn.Module):\n",
    "    def __init__(self, num_class, SF_list, normal_channel=False):\n",
    "        super(get_model, self).__init__()\n",
    "        in_channel = 3 if normal_channel else 1\n",
    "        self.normal_channel = normal_channel\n",
    "        self.SF1, self.SF2, self.SF3 = SF_list[2], SF_list[1], SF_list[0]\n",
    "\n",
    "        self.layer0 = EncodingLayer(self.SF3, in_channel, [16, 16]) \n",
    "        self.layer1 = EncodingLayer(self.SF3, 16, [32, 32])   \n",
    "        self.layer2 = EncodingLayer(self.SF2, 32, [64, 64])   \n",
    "        self.layer3 = EncodingLayer(self.SF1, 64, [128, 128])   \n",
    "\n",
    "        self.smp1 = SphericalMaxPooling(self.SF3, self.SF2)\n",
    "        self.smp2 = SphericalMaxPooling(self.SF2, self.SF1)\n",
    "\n",
    "        self.fc1 = nn.Linear(480, 512)\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        # self.drop1 = nn.Dropout(0.4)\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        # self.drop2 = nn.Dropout(0.5)\n",
    "        self.fc3 = nn.Linear(128, num_class)\n",
    "\n",
    "    def forward(self, xyz):\n",
    "        B, _, _ = xyz.shape      #Bx1x642\n",
    "        # if self.normal_channel:\n",
    "        #     norm = xyz[:, 3:, :]\n",
    "        #     xyz = xyz[:, :3, :]\n",
    "        # else:\n",
    "        #     norm = None\n",
    "        # print(xyz.shape)\n",
    "\n",
    "        \n",
    "\n",
    "        l0_inner, l0_outer, l0_feature = self.layer0(xyz)       #Bx16x642\n",
    "        # SphericalMaxPooling(l0_feature, self.SF3, self.SF3)\n",
    "        print(l0_inner.shape, l0_feature.shape)\n",
    "\n",
    "        l1_inner, l1_outer, l1_feature = self.layer1(l0_feature)    #Bx32x642\n",
    "        l1_out = self.smp1(l1_feature)     #Bx32x162\n",
    "        print(l1_inner.shape, l1_out.shape)\n",
    "        \n",
    "        l2_inner, l2_outer, l2_feature = self.layer2(l1_out)     #Bx64x162\n",
    "        l2_out = self.smp2(l2_feature)     #Bx64x42\n",
    "        print(l2_inner.shape, l2_out.shape)\n",
    "        \n",
    "        l3_inner, l3_outer, l3_feature = self.layer3(l2_out)     #Bx128x42\n",
    "        print(l3_inner.shape, l3_feature.shape)\n",
    "\n",
    "        # l0_inner = torch.max(l0_inner, 2)[0]\n",
    "        # l0_feature = torch.max(l0_feature, 2)[0]\n",
    "        # l1_inner = torch.max(l1_inner, 2)[0]\n",
    "        # l1_feature = torch.max(l1_feature, 2)[0]\n",
    "        # l2_inner = torch.max(l2_inner, 2)[0]\n",
    "        # l2_feature = torch.max(l2_feature, 2)[0]\n",
    "        # l3_inner = torch.max(l3_inner, 2)[0]\n",
    "        # l3_feature = torch.max(l3_feature, 2)[0]\n",
    "\n",
    "        out_feature = torch.cat((l0_inner, l0_outer, l1_inner, l1_outer, l2_inner, l2_outer, l3_inner, l3_outer), 1)\n",
    "\n",
    "        print(out_feature.shape)\n",
    "        x = out_feature.view(B, -1)\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = F.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        x = F.log_softmax(x, -1)\n",
    "\n",
    "        return x, l3_feature\n",
    "\n",
    "\n",
    "class get_loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(get_loss, self).__init__()\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        total_loss = F.nll_loss(pred, target)\n",
    "\n",
    "        return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchsummary\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# from model_utils import EncodingLayer, SphericalMaxPooling\n",
    "SF3 = np.random.randint(0, 3, (642, 3)), np.random.randint(-1, 642, (642, 6))\n",
    "SF2 = np.random.randint(0, 3, (162, 3)), np.random.randint(-1, 162, (162, 6))\n",
    "SF1 = np.random.randint(0, 3, (42, 3)), np.random.randint(-1, 42, (42, 6))\n",
    "SFs = [SF3, SF2, SF1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncodingLayer(nn.Module):\n",
    "    def __init__(self, SF, in_channel, mlp, residual=False):\n",
    "        super(EncodingLayer, self).__init__()\n",
    "        self.SF = SF\n",
    "        self.mlp_convs = nn.ModuleList()\n",
    "        self.mlp_bns = nn.ModuleList()\n",
    "        last_channel = in_channel*2\n",
    "\n",
    "        for out_channel in mlp:\n",
    "            self.mlp_convs.append(nn.Conv2d(last_channel, out_channel, 1))  #왜 2d로 함?\n",
    "            self.mlp_bns.append(nn.BatchNorm2d(out_channel))\n",
    "            last_channel = out_channel\n",
    "\n",
    "    def forward(self, points):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "            points: input points data, [B, C, N]\n",
    "        Return:\n",
    "            new_xyz: sampled points position data, [B, C', N]\n",
    "        \"\"\"\n",
    "        points = points.permute(0, 2, 1)    #BxNxC\n",
    "\n",
    "        feature_block = makeInputData(points, self.SF)      #BxNx6x2C\n",
    "        new_feature = feature_block.permute(0, 3, 2, 1)    #Bx2Cx6xN\n",
    "\n",
    "        for i, conv in enumerate(self.mlp_convs):\n",
    "            bn = self.mlp_bns[i]\n",
    "            new_feature =  F.relu(bn(conv(new_feature)))\n",
    "\n",
    "            if i==0:\n",
    "                inner_feature = new_feature\n",
    "        \n",
    "        new_feature = torch.max(new_feature, 2)[0] #[B, C', N] - maxpooling of conv (1 kernel)\n",
    "        inner_feature = torch.max(inner_feature, 2)[0]\n",
    "\n",
    "        inner_feature = torch.max(inner_feature, 2)[0]\n",
    "        out_feature = torch.max(new_feature, 2)[0]\n",
    "        # print(\"ff\")\n",
    "#         new_feature = new_feature.permute(0, 2, 1)\n",
    "#         print(new_feature.shape)\n",
    "\n",
    "        return inner_feature, out_feature, new_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(20, SFs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 16]) torch.Size([20, 16, 642])\n",
      "torch.Size([20, 32]) torch.Size([20, 32, 162])\n",
      "torch.Size([20, 64]) torch.Size([20, 64, 42])\n",
      "torch.Size([20, 128]) torch.Size([20, 128, 42])\n",
      "torch.Size([20, 480])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[-2.9822, -3.0191, -2.9724, -2.9181, -3.0396, -3.0406, -2.9642, -3.0403,\n",
       "          -3.0055, -3.0040, -2.9219, -3.0157, -3.0636, -3.0404, -2.9077, -3.0463,\n",
       "          -2.9752, -3.0383, -2.9233, -3.0189],\n",
       "         [-2.9822, -3.0191, -2.9724, -2.9181, -3.0396, -3.0406, -2.9642, -3.0403,\n",
       "          -3.0055, -3.0040, -2.9219, -3.0157, -3.0636, -3.0404, -2.9077, -3.0463,\n",
       "          -2.9752, -3.0383, -2.9233, -3.0189],\n",
       "         [-2.9822, -3.0191, -2.9724, -2.9181, -3.0396, -3.0406, -2.9642, -3.0403,\n",
       "          -3.0055, -3.0040, -2.9219, -3.0157, -3.0636, -3.0404, -2.9077, -3.0463,\n",
       "          -2.9752, -3.0383, -2.9233, -3.0189],\n",
       "         [-2.9822, -3.0191, -2.9724, -2.9181, -3.0396, -3.0406, -2.9642, -3.0403,\n",
       "          -3.0055, -3.0040, -2.9219, -3.0157, -3.0636, -3.0404, -2.9077, -3.0463,\n",
       "          -2.9752, -3.0383, -2.9233, -3.0189],\n",
       "         [-2.9822, -3.0191, -2.9724, -2.9181, -3.0396, -3.0406, -2.9642, -3.0403,\n",
       "          -3.0055, -3.0040, -2.9219, -3.0157, -3.0636, -3.0404, -2.9077, -3.0463,\n",
       "          -2.9752, -3.0383, -2.9233, -3.0189],\n",
       "         [-2.9822, -3.0191, -2.9724, -2.9181, -3.0396, -3.0406, -2.9642, -3.0403,\n",
       "          -3.0055, -3.0040, -2.9219, -3.0157, -3.0636, -3.0404, -2.9077, -3.0463,\n",
       "          -2.9752, -3.0383, -2.9233, -3.0189],\n",
       "         [-2.9822, -3.0191, -2.9724, -2.9181, -3.0396, -3.0406, -2.9642, -3.0403,\n",
       "          -3.0055, -3.0040, -2.9219, -3.0157, -3.0636, -3.0404, -2.9077, -3.0463,\n",
       "          -2.9752, -3.0383, -2.9233, -3.0189],\n",
       "         [-2.9822, -3.0191, -2.9724, -2.9181, -3.0396, -3.0406, -2.9642, -3.0403,\n",
       "          -3.0055, -3.0040, -2.9219, -3.0157, -3.0636, -3.0404, -2.9077, -3.0463,\n",
       "          -2.9752, -3.0383, -2.9233, -3.0189],\n",
       "         [-2.9822, -3.0191, -2.9724, -2.9181, -3.0396, -3.0406, -2.9642, -3.0403,\n",
       "          -3.0055, -3.0040, -2.9219, -3.0157, -3.0636, -3.0404, -2.9077, -3.0463,\n",
       "          -2.9752, -3.0383, -2.9233, -3.0189],\n",
       "         [-2.9822, -3.0191, -2.9724, -2.9181, -3.0396, -3.0406, -2.9642, -3.0403,\n",
       "          -3.0055, -3.0040, -2.9219, -3.0157, -3.0636, -3.0404, -2.9077, -3.0463,\n",
       "          -2.9752, -3.0383, -2.9233, -3.0189],\n",
       "         [-2.9822, -3.0191, -2.9724, -2.9181, -3.0396, -3.0406, -2.9642, -3.0403,\n",
       "          -3.0055, -3.0040, -2.9219, -3.0157, -3.0636, -3.0404, -2.9077, -3.0463,\n",
       "          -2.9752, -3.0383, -2.9233, -3.0189],\n",
       "         [-2.9822, -3.0191, -2.9724, -2.9181, -3.0396, -3.0406, -2.9642, -3.0403,\n",
       "          -3.0055, -3.0040, -2.9219, -3.0157, -3.0636, -3.0404, -2.9077, -3.0463,\n",
       "          -2.9752, -3.0383, -2.9233, -3.0189],\n",
       "         [-2.9822, -3.0191, -2.9724, -2.9181, -3.0396, -3.0406, -2.9642, -3.0403,\n",
       "          -3.0055, -3.0040, -2.9219, -3.0157, -3.0636, -3.0404, -2.9077, -3.0463,\n",
       "          -2.9752, -3.0383, -2.9233, -3.0189],\n",
       "         [-2.9822, -3.0191, -2.9724, -2.9181, -3.0396, -3.0406, -2.9642, -3.0403,\n",
       "          -3.0055, -3.0040, -2.9219, -3.0157, -3.0636, -3.0404, -2.9077, -3.0463,\n",
       "          -2.9752, -3.0383, -2.9233, -3.0189],\n",
       "         [-2.9822, -3.0191, -2.9724, -2.9181, -3.0396, -3.0406, -2.9642, -3.0403,\n",
       "          -3.0055, -3.0040, -2.9219, -3.0157, -3.0636, -3.0404, -2.9077, -3.0463,\n",
       "          -2.9752, -3.0383, -2.9233, -3.0189],\n",
       "         [-2.9822, -3.0191, -2.9724, -2.9181, -3.0396, -3.0406, -2.9642, -3.0403,\n",
       "          -3.0055, -3.0040, -2.9219, -3.0157, -3.0636, -3.0404, -2.9077, -3.0463,\n",
       "          -2.9752, -3.0383, -2.9233, -3.0189],\n",
       "         [-2.9822, -3.0191, -2.9724, -2.9181, -3.0396, -3.0406, -2.9642, -3.0403,\n",
       "          -3.0055, -3.0040, -2.9219, -3.0157, -3.0636, -3.0404, -2.9077, -3.0463,\n",
       "          -2.9752, -3.0383, -2.9233, -3.0189],\n",
       "         [-2.9822, -3.0191, -2.9724, -2.9181, -3.0396, -3.0406, -2.9642, -3.0403,\n",
       "          -3.0055, -3.0040, -2.9219, -3.0157, -3.0636, -3.0404, -2.9077, -3.0463,\n",
       "          -2.9752, -3.0383, -2.9233, -3.0189],\n",
       "         [-2.9822, -3.0191, -2.9724, -2.9181, -3.0396, -3.0406, -2.9642, -3.0403,\n",
       "          -3.0055, -3.0040, -2.9219, -3.0157, -3.0636, -3.0404, -2.9077, -3.0463,\n",
       "          -2.9752, -3.0383, -2.9233, -3.0189],\n",
       "         [-2.9822, -3.0191, -2.9724, -2.9181, -3.0396, -3.0406, -2.9642, -3.0403,\n",
       "          -3.0055, -3.0040, -2.9219, -3.0157, -3.0636, -3.0404, -2.9077, -3.0463,\n",
       "          -2.9752, -3.0383, -2.9233, -3.0189]], grad_fn=<LogSoftmaxBackward>),\n",
       " tensor([[[0.1422, 0.1422, 0.1422,  ..., 0.1422, 0.1422, 0.1422],\n",
       "          [0.1423, 0.1423, 0.1423,  ..., 0.1423, 0.1423, 0.1423],\n",
       "          [0.1422, 0.1422, 0.1422,  ..., 0.1422, 0.1422, 0.1422],\n",
       "          ...,\n",
       "          [0.0000, 7.0270, 0.0000,  ..., 0.0000, 0.0000, 7.0270],\n",
       "          [0.0000, 7.0280, 0.0000,  ..., 0.0000, 0.0000, 7.0280],\n",
       "          [0.1422, 0.1422, 0.1422,  ..., 0.1422, 0.1422, 0.1422]],\n",
       " \n",
       "         [[0.1422, 0.1422, 0.1422,  ..., 0.1422, 0.1422, 0.1422],\n",
       "          [0.1423, 0.1423, 0.1423,  ..., 0.1423, 0.1423, 0.1423],\n",
       "          [0.1422, 0.1422, 0.1422,  ..., 0.1422, 0.1422, 0.1422],\n",
       "          ...,\n",
       "          [0.0000, 7.0270, 0.0000,  ..., 0.0000, 0.0000, 7.0270],\n",
       "          [0.0000, 7.0280, 0.0000,  ..., 0.0000, 0.0000, 7.0280],\n",
       "          [0.1422, 0.1422, 0.1422,  ..., 0.1422, 0.1422, 0.1422]],\n",
       " \n",
       "         [[0.1422, 0.1422, 0.1422,  ..., 0.1422, 0.1422, 0.1422],\n",
       "          [0.1423, 0.1423, 0.1423,  ..., 0.1423, 0.1423, 0.1423],\n",
       "          [0.1422, 0.1422, 0.1422,  ..., 0.1422, 0.1422, 0.1422],\n",
       "          ...,\n",
       "          [0.0000, 7.0270, 0.0000,  ..., 0.0000, 0.0000, 7.0270],\n",
       "          [0.0000, 7.0280, 0.0000,  ..., 0.0000, 0.0000, 7.0280],\n",
       "          [0.1422, 0.1422, 0.1422,  ..., 0.1422, 0.1422, 0.1422]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.1422, 0.1422, 0.1422,  ..., 0.1422, 0.1422, 0.1422],\n",
       "          [0.1423, 0.1423, 0.1423,  ..., 0.1423, 0.1423, 0.1423],\n",
       "          [0.1422, 0.1422, 0.1422,  ..., 0.1422, 0.1422, 0.1422],\n",
       "          ...,\n",
       "          [0.0000, 7.0270, 0.0000,  ..., 0.0000, 0.0000, 7.0270],\n",
       "          [0.0000, 7.0280, 0.0000,  ..., 0.0000, 0.0000, 7.0280],\n",
       "          [0.1422, 0.1422, 0.1422,  ..., 0.1422, 0.1422, 0.1422]],\n",
       " \n",
       "         [[0.1422, 0.1422, 0.1422,  ..., 0.1422, 0.1422, 0.1422],\n",
       "          [0.1423, 0.1423, 0.1423,  ..., 0.1423, 0.1423, 0.1423],\n",
       "          [0.1422, 0.1422, 0.1422,  ..., 0.1422, 0.1422, 0.1422],\n",
       "          ...,\n",
       "          [0.0000, 7.0270, 0.0000,  ..., 0.0000, 0.0000, 7.0270],\n",
       "          [0.0000, 7.0280, 0.0000,  ..., 0.0000, 0.0000, 7.0280],\n",
       "          [0.1422, 0.1422, 0.1422,  ..., 0.1422, 0.1422, 0.1422]],\n",
       " \n",
       "         [[0.1422, 0.1422, 0.1422,  ..., 0.1422, 0.1422, 0.1422],\n",
       "          [0.1423, 0.1423, 0.1423,  ..., 0.1423, 0.1423, 0.1423],\n",
       "          [0.1422, 0.1422, 0.1422,  ..., 0.1422, 0.1422, 0.1422],\n",
       "          ...,\n",
       "          [0.0000, 7.0270, 0.0000,  ..., 0.0000, 0.0000, 7.0270],\n",
       "          [0.0000, 7.0280, 0.0000,  ..., 0.0000, 0.0000, 7.0280],\n",
       "          [0.1422, 0.1422, 0.1422,  ..., 0.1422, 0.1422, 0.1422]]],\n",
       "        grad_fn=<MaxBackward0>))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.zeros(20, 1, 642)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def readIcosahedron(file_path, n_vertices):       #정리해놓은 Icosahedron 파일 읽어서 SF return\n",
    "    vertices = np.zeros((n_vertices, 3))\n",
    "    near_idx = np.zeros((n_vertices, 6)) - 1\n",
    "\n",
    "    cnt_v = 0\n",
    "    cnt_n = 0\n",
    "\n",
    "    with open(file_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            temp = line.split()\n",
    "\n",
    "            if temp[0] == 'v':\n",
    "                vertices[cnt_v, 0] = temp[1]\n",
    "                vertices[cnt_v, 1] = temp[2]\n",
    "                vertices[cnt_v, 2] = temp[3]\n",
    "                cnt_v += 1\n",
    "\n",
    "            if temp[0] == 'np':\n",
    "                near_idx[cnt_n, 0] = temp[1]\n",
    "                near_idx[cnt_n, 1] = temp[2]\n",
    "                near_idx[cnt_n, 2] = temp[3]\n",
    "                near_idx[cnt_n, 3] = temp[4]\n",
    "                near_idx[cnt_n, 4] = temp[5]\n",
    "                if len(temp)>=7:\n",
    "                    near_idx[cnt_n, 5] = temp[6]\n",
    "\n",
    "                cnt_n += 1\n",
    "\n",
    "    return vertices, near_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SF1 = readIcosahedron('./data_utils/SF1.txt', 42)\n",
    "SF2 = readIcosahedron('./data_utils/SF2.txt', 162)\n",
    "SF3 = readIcosahedron('./data_utils/SF3.txt', 642)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_v, in_ni = SF3\n",
    "out_v, out_ni = SF2\n",
    "\n",
    "in_nvertices = in_v.shape[0]\n",
    "out_nvertices = out_v.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "642"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_nvertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.525731  0.850651  0.      ] [-0.525731  0.850651  0.      ]\n",
      "[0.525731 0.850651 0.      ] [0.525731 0.850651 0.      ]\n",
      "[-0.525731 -0.850651  0.      ] [-0.525731 -0.850651  0.      ]\n",
      "[ 0.525731 -0.850651  0.      ] [ 0.525731 -0.850651  0.      ]\n",
      "[ 0.       -0.525731  0.850651] [ 0.       -0.525731  0.850651]\n",
      "[0.       0.525731 0.850651] [0.       0.525731 0.850651]\n",
      "[ 0.       -0.525731 -0.850651] [ 0.       -0.525731 -0.850651]\n",
      "[ 0.        0.525731 -0.850651] [ 0.        0.525731 -0.850651]\n",
      "[ 0.850651  0.       -0.525731] [ 0.850651  0.       -0.525731]\n",
      "[0.850651 0.       0.525731] [0.850651 0.       0.525731]\n",
      "[-0.850651  0.       -0.525731] [-0.850651  0.       -0.525731]\n",
      "[-0.850651  0.        0.525731] [-0.850651  0.        0.525731]\n",
      "[-0.809017  0.5       0.309017] [-0.809017  0.5       0.309017]\n",
      "[-0.5       0.309017  0.809017] [-0.5       0.309017  0.809017]\n",
      "[-0.309017  0.809017  0.5     ] [-0.309017  0.809017  0.5     ]\n",
      "[0.309017 0.809017 0.5     ] [0.309017 0.809017 0.5     ]\n",
      "[0. 1. 0.] [0. 1. 0.]\n",
      "[ 0.309017  0.809017 -0.5     ] [ 0.309017  0.809017 -0.5     ]\n",
      "[-0.309017  0.809017 -0.5     ] [-0.309017  0.809017 -0.5     ]\n",
      "[-0.5       0.309017 -0.809017] [-0.5       0.309017 -0.809017]\n",
      "[-0.809017  0.5      -0.309017] [-0.809017  0.5      -0.309017]\n",
      "[-1.  0.  0.] [-1.  0.  0.]\n",
      "[0.5      0.309017 0.809017] [0.5      0.309017 0.809017]\n",
      "[0.809017 0.5      0.309017] [0.809017 0.5      0.309017]\n",
      "[-0.5      -0.309017  0.809017] [-0.5      -0.309017  0.809017]\n",
      "[0. 0. 1.] [0. 0. 1.]\n",
      "[-0.809017 -0.5      -0.309017] [-0.809017 -0.5      -0.309017]\n",
      "[-0.809017 -0.5       0.309017] [-0.809017 -0.5       0.309017]\n",
      "[ 0.  0. -1.] [ 0.  0. -1.]\n",
      "[-0.5      -0.309017 -0.809017] [-0.5      -0.309017 -0.809017]\n",
      "[ 0.809017  0.5      -0.309017] [ 0.809017  0.5      -0.309017]\n",
      "[ 0.5       0.309017 -0.809017] [ 0.5       0.309017 -0.809017]\n",
      "[ 0.809017 -0.5       0.309017] [ 0.809017 -0.5       0.309017]\n",
      "[ 0.5      -0.309017  0.809017] [ 0.5      -0.309017  0.809017]\n",
      "[ 0.309017 -0.809017  0.5     ] [ 0.309017 -0.809017  0.5     ]\n",
      "[-0.309017 -0.809017  0.5     ] [-0.309017 -0.809017  0.5     ]\n",
      "[ 0. -1.  0.] [ 0. -1.  0.]\n",
      "[-0.309017 -0.809017 -0.5     ] [-0.309017 -0.809017 -0.5     ]\n",
      "[ 0.309017 -0.809017 -0.5     ] [ 0.309017 -0.809017 -0.5     ]\n",
      "[ 0.5      -0.309017 -0.809017] [ 0.5      -0.309017 -0.809017]\n",
      "[ 0.809017 -0.5      -0.309017] [ 0.809017 -0.5      -0.309017]\n",
      "[1. 0. 0.] [1. 0. 0.]\n",
      "[-0.69378   0.702046  0.160622] [-0.69378   0.702046  0.160622]\n",
      "[-0.587785  0.688191  0.425325] [-0.587785  0.688191  0.425325]\n",
      "[-0.433889  0.862668  0.259892] [-0.433889  0.862668  0.259892]\n",
      "[-0.862668  0.259892  0.433889] [-0.862668  0.259892  0.433889]\n",
      "[-0.702046  0.160622  0.69378 ] [-0.702046  0.160622  0.69378 ]\n",
      "[-0.688191  0.425325  0.587785] [-0.688191  0.425325  0.587785]\n",
      "[-0.259892  0.433889  0.862668] [-0.259892  0.433889  0.862668]\n",
      "[-0.160622  0.69378   0.702046] [-0.160622  0.69378   0.702046]\n",
      "[-0.425325  0.587785  0.688191] [-0.425325  0.587785  0.688191]\n",
      "[-0.16246   0.951057  0.262866] [-0.16246   0.951057  0.262866]\n",
      "[-0.273267  0.961938  0.      ] [-0.273267  0.961938  0.      ]\n",
      "[0.160622 0.69378  0.702046] [0.160622 0.69378  0.702046]\n",
      "[0.       0.850651 0.525731] [0.       0.850651 0.525731]\n",
      "[0.433889 0.862668 0.259892] [0.433889 0.862668 0.259892]\n",
      "[0.273267 0.961938 0.      ] [0.273267 0.961938 0.      ]\n",
      "[0.16246  0.951057 0.262866] [0.16246  0.951057 0.262866]\n",
      "[-0.16246   0.951057 -0.262866] [-0.16246   0.951057 -0.262866]\n",
      "[-0.433889  0.862668 -0.259892] [-0.433889  0.862668 -0.259892]\n",
      "[ 0.433889  0.862668 -0.259892] [ 0.433889  0.862668 -0.259892]\n",
      "[ 0.16246   0.951057 -0.262866] [ 0.16246   0.951057 -0.262866]\n",
      "[ 0.160622  0.69378  -0.702046] [ 0.160622  0.69378  -0.702046]\n",
      "[-0.160622  0.69378  -0.702046] [-0.160622  0.69378  -0.702046]\n",
      "[ 0.        0.850651 -0.525731] [ 0.        0.850651 -0.525731]\n",
      "[-0.587785  0.688191 -0.425325] [-0.587785  0.688191 -0.425325]\n",
      "[-0.69378   0.702046 -0.160622] [-0.69378   0.702046 -0.160622]\n",
      "[-0.259892  0.433889 -0.862668] [-0.259892  0.433889 -0.862668]\n",
      "[-0.425325  0.587785 -0.688191] [-0.425325  0.587785 -0.688191]\n",
      "[-0.702046  0.160622 -0.69378 ] [-0.702046  0.160622 -0.69378 ]\n",
      "[-0.862668  0.259892 -0.433889] [-0.862668  0.259892 -0.433889]\n",
      "[-0.688191  0.425325 -0.587785] [-0.688191  0.425325 -0.587785]\n",
      "[-0.850651  0.525731  0.      ] [-0.850651  0.525731  0.      ]\n",
      "[-0.961938  0.       -0.273267] [-0.961938  0.       -0.273267]\n",
      "[-0.951057  0.262866 -0.16246 ] [-0.951057  0.262866 -0.16246 ]\n",
      "[-0.961938  0.        0.273267] [-0.961938  0.        0.273267]\n",
      "[-0.951057  0.262866  0.16246 ] [-0.951057  0.262866  0.16246 ]\n",
      "[0.587785 0.688191 0.425325] [0.587785 0.688191 0.425325]\n",
      "[0.69378  0.702046 0.160622] [0.69378  0.702046 0.160622]\n",
      "[0.259892 0.433889 0.862668] [0.259892 0.433889 0.862668]\n",
      "[0.425325 0.587785 0.688191] [0.425325 0.587785 0.688191]\n",
      "[0.702046 0.160622 0.69378 ] [0.702046 0.160622 0.69378 ]\n",
      "[0.862668 0.259892 0.433889] [0.862668 0.259892 0.433889]\n",
      "[0.688191 0.425325 0.587785] [0.688191 0.425325 0.587785]\n",
      "[-0.262866  0.16246   0.951057] [-0.262866  0.16246   0.951057]\n",
      "[0.       0.273267 0.961938] [0.       0.273267 0.961938]\n",
      "[-0.702046 -0.160622  0.69378 ] [-0.702046 -0.160622  0.69378 ]\n",
      "[-0.525731  0.        0.850651] [-0.525731  0.        0.850651]\n",
      "[-0.259892 -0.433889  0.862668] [-0.259892 -0.433889  0.862668]\n",
      "[ 0.       -0.273267  0.961938] [ 0.       -0.273267  0.961938]\n",
      "[-0.262866 -0.16246   0.951057] [-0.262866 -0.16246   0.951057]\n",
      "[-0.951057 -0.262866  0.16246 ] [-0.951057 -0.262866  0.16246 ]\n",
      "[-0.862668 -0.259892  0.433889] [-0.862668 -0.259892  0.433889]\n",
      "[-0.862668 -0.259892 -0.433889] [-0.862668 -0.259892 -0.433889]\n",
      "[-0.951057 -0.262866 -0.16246 ] [-0.951057 -0.262866 -0.16246 ]\n",
      "[-0.69378  -0.702046 -0.160622] [-0.69378  -0.702046 -0.160622]\n",
      "[-0.69378  -0.702046  0.160622] [-0.69378  -0.702046  0.160622]\n",
      "[-0.850651 -0.525731  0.      ] [-0.850651 -0.525731  0.      ]\n",
      "[-0.525731  0.       -0.850651] [-0.525731  0.       -0.850651]\n",
      "[-0.702046 -0.160622 -0.69378 ] [-0.702046 -0.160622 -0.69378 ]\n",
      "[ 0.        0.273267 -0.961938] [ 0.        0.273267 -0.961938]\n",
      "[-0.262866  0.16246  -0.951057] [-0.262866  0.16246  -0.951057]\n",
      "[ 0.       -0.273267 -0.961938] [ 0.       -0.273267 -0.961938]\n",
      "[-0.259892 -0.433889 -0.862668] [-0.259892 -0.433889 -0.862668]\n",
      "[-0.262866 -0.16246  -0.951057] [-0.262866 -0.16246  -0.951057]\n",
      "[ 0.425325  0.587785 -0.688191] [ 0.425325  0.587785 -0.688191]\n",
      "[ 0.259892  0.433889 -0.862668] [ 0.259892  0.433889 -0.862668]\n",
      "[ 0.69378   0.702046 -0.160622] [ 0.69378   0.702046 -0.160622]\n",
      "[ 0.587785  0.688191 -0.425325] [ 0.587785  0.688191 -0.425325]\n",
      "[ 0.862668  0.259892 -0.433889] [ 0.862668  0.259892 -0.433889]\n",
      "[ 0.702046  0.160622 -0.69378 ] [ 0.702046  0.160622 -0.69378 ]\n",
      "[ 0.688191  0.425325 -0.587785] [ 0.688191  0.425325 -0.587785]\n",
      "[ 0.69378  -0.702046  0.160622] [ 0.69378  -0.702046  0.160622]\n",
      "[ 0.587785 -0.688191  0.425325] [ 0.587785 -0.688191  0.425325]\n",
      "[ 0.433889 -0.862668  0.259892] [ 0.433889 -0.862668  0.259892]\n",
      "[ 0.862668 -0.259892  0.433889] [ 0.862668 -0.259892  0.433889]\n",
      "[ 0.702046 -0.160622  0.69378 ] [ 0.702046 -0.160622  0.69378 ]\n",
      "[ 0.688191 -0.425325  0.587785] [ 0.688191 -0.425325  0.587785]\n",
      "[ 0.259892 -0.433889  0.862668] [ 0.259892 -0.433889  0.862668]\n",
      "[ 0.160622 -0.69378   0.702046] [ 0.160622 -0.69378   0.702046]\n",
      "[ 0.425325 -0.587785  0.688191] [ 0.425325 -0.587785  0.688191]\n",
      "[ 0.16246  -0.951057  0.262866] [ 0.16246  -0.951057  0.262866]\n",
      "[ 0.273267 -0.961938  0.      ] [ 0.273267 -0.961938  0.      ]\n",
      "[-0.160622 -0.69378   0.702046] [-0.160622 -0.69378   0.702046]\n",
      "[ 0.       -0.850651  0.525731] [ 0.       -0.850651  0.525731]\n",
      "[-0.433889 -0.862668  0.259892] [-0.433889 -0.862668  0.259892]\n",
      "[-0.273267 -0.961938  0.      ] [-0.273267 -0.961938  0.      ]\n",
      "[-0.16246  -0.951057  0.262866] [-0.16246  -0.951057  0.262866]\n",
      "[ 0.16246  -0.951057 -0.262866] [ 0.16246  -0.951057 -0.262866]\n",
      "[ 0.433889 -0.862668 -0.259892] [ 0.433889 -0.862668 -0.259892]\n",
      "[-0.433889 -0.862668 -0.259892] [-0.433889 -0.862668 -0.259892]\n",
      "[-0.16246  -0.951057 -0.262866] [-0.16246  -0.951057 -0.262866]\n",
      "[-0.160622 -0.69378  -0.702046] [-0.160622 -0.69378  -0.702046]\n",
      "[ 0.160622 -0.69378  -0.702046] [ 0.160622 -0.69378  -0.702046]\n",
      "[ 0.       -0.850651 -0.525731] [ 0.       -0.850651 -0.525731]\n",
      "[ 0.587785 -0.688191 -0.425325] [ 0.587785 -0.688191 -0.425325]\n",
      "[ 0.69378  -0.702046 -0.160622] [ 0.69378  -0.702046 -0.160622]\n",
      "[ 0.259892 -0.433889 -0.862668] [ 0.259892 -0.433889 -0.862668]\n",
      "[ 0.425325 -0.587785 -0.688191] [ 0.425325 -0.587785 -0.688191]\n",
      "[ 0.702046 -0.160622 -0.69378 ] [ 0.702046 -0.160622 -0.69378 ]\n",
      "[ 0.862668 -0.259892 -0.433889] [ 0.862668 -0.259892 -0.433889]\n",
      "[ 0.688191 -0.425325 -0.587785] [ 0.688191 -0.425325 -0.587785]\n",
      "[ 0.850651 -0.525731  0.      ] [ 0.850651 -0.525731  0.      ]\n",
      "[ 0.961938  0.       -0.273267] [ 0.961938  0.       -0.273267]\n",
      "[ 0.951057 -0.262866 -0.16246 ] [ 0.951057 -0.262866 -0.16246 ]\n",
      "[0.961938 0.       0.273267] [0.961938 0.       0.273267]\n",
      "[ 0.951057 -0.262866  0.16246 ] [ 0.951057 -0.262866  0.16246 ]\n",
      "[ 0.262866 -0.16246   0.951057] [ 0.262866 -0.16246   0.951057]\n",
      "[0.525731 0.       0.850651] [0.525731 0.       0.850651]\n",
      "[0.262866 0.16246  0.951057] [0.262866 0.16246  0.951057]\n",
      "[-0.587785 -0.688191  0.425325] [-0.587785 -0.688191  0.425325]\n",
      "[-0.425325 -0.587785  0.688191] [-0.425325 -0.587785  0.688191]\n",
      "[-0.688191 -0.425325  0.587785] [-0.688191 -0.425325  0.587785]\n",
      "[-0.425325 -0.587785 -0.688191] [-0.425325 -0.587785 -0.688191]\n",
      "[-0.587785 -0.688191 -0.425325] [-0.587785 -0.688191 -0.425325]\n",
      "[-0.688191 -0.425325 -0.587785] [-0.688191 -0.425325 -0.587785]\n",
      "[ 0.525731  0.       -0.850651] [ 0.525731  0.       -0.850651]\n",
      "[ 0.262866 -0.16246  -0.951057] [ 0.262866 -0.16246  -0.951057]\n",
      "[ 0.262866  0.16246  -0.951057] [ 0.262866  0.16246  -0.951057]\n",
      "[0.951057 0.262866 0.16246 ] [0.951057 0.262866 0.16246 ]\n",
      "[ 0.951057  0.262866 -0.16246 ] [ 0.951057  0.262866 -0.16246 ]\n",
      "[0.850651 0.525731 0.      ] [0.850651 0.525731 0.      ]\n"
     ]
    }
   ],
   "source": [
    "with open('./data_utils/SF3toSF2_idxs.txt', 'w') as f:\n",
    "    for i, out_xyz in enumerate(out_v):\n",
    "        for j, in_xyz in enumerate(in_v):\n",
    "            if out_xyz[0] == in_xyz[0] and out_xyz[1] == in_xyz[1] and out_xyz[2] == in_xyz[2]:\n",
    "                f.write('%d\\n' % j)\n",
    "#                 print(out_xyz, in_xyz)\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(out_path, 'w') as f:\n",
    "                for v in vertices:\n",
    "                    f.write('v')\n",
    "                    for p in v:\n",
    "                        f.write(' %f' % p)\n",
    "                    f.write(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
