{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchsummary\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# from model_utils import EncodingLayer, SphericalMaxPooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SF1 = np.random.randint(0, 3, (642, 3)), np.random.randint(-1, 642, (642, 6))\n",
    "SF2 = np.random.randint(0, 3, (162, 3)), np.random.randint(-1, 162, (162, 6))\n",
    "SF3 = np.random.randint(0, 3, (42, 3)), np.random.randint(-1, 42, (42, 6))\n",
    "SFs = [SF1, SF2, SF3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readIcosahedron(file_path, n_vertices):       #정리해놓은 Icosahedron 파일 읽어서 SF return\n",
    "    vertices = np.zeros((n_vertices, 3))\n",
    "    near_idx = np.zeros((n_vertices, 6)) - 1\n",
    "    faces = np.zeros(((n_vertices-2)*2, 3))\n",
    "\n",
    "    cnt_v = 0\n",
    "    cnt_n = 0\n",
    "    cnt_f = 0   \n",
    "\n",
    "    with open(file_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            temp = line.split()\n",
    "\n",
    "            if temp[0] == 'v':\n",
    "                vertices[cnt_v, 0] = temp[1]\n",
    "                vertices[cnt_v, 1] = temp[2]\n",
    "                vertices[cnt_v, 2] = temp[3]\n",
    "                cnt_v += 1\n",
    "\n",
    "            if temp[0] == 'f':\n",
    "                faces[cnt_f, 0] = temp[1]\n",
    "                faces[cnt_f, 1] = temp[2]\n",
    "                faces[cnt_f, 2] = temp[3]\n",
    "                cnt_f += 1\n",
    "\n",
    "            if temp[0] == 'np':\n",
    "                near_idx[cnt_n, 0] = temp[1]\n",
    "                near_idx[cnt_n, 1] = temp[2]\n",
    "                near_idx[cnt_n, 2] = temp[3]\n",
    "                near_idx[cnt_n, 3] = temp[4]\n",
    "                near_idx[cnt_n, 4] = temp[5]\n",
    "                if len(temp)>=7:\n",
    "                    near_idx[cnt_n, 5] = temp[6]\n",
    "\n",
    "                cnt_n += 1\n",
    "\n",
    "    return vertices, near_idx, faces\n",
    "\n",
    "SF1 = readIcosahedron('./data_utils/SF1.txt', 42)\n",
    "SF2 = readIcosahedron('./data_utils/SF2.txt', 162)\n",
    "SF3 = readIcosahedron('./data_utils/SF3.txt', 642)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((42, 3), (80, 3))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SFs = [SF1, SF2, SF3]\n",
    "v, n, f = SF1\n",
    "v.shape, f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.SFCNN_seg import get_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xyz = torch.rand((8, 3, 2048)).cuda()\n",
    "projected = torch.rand(8, 1, 642).cuda()\n",
    "cls_label = torch.randint(16, size=(8, 16)).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(16, SFs).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 64, 642])\n",
      "torch.Size([8, 128, 642])\n",
      "torch.Size([8, 256, 162])\n",
      "torch.Size([8, 1024, 42])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "All input tensors must be on the same device. Received cpu and cuda:0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-8b7c0fa04ed3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxyz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprojected\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/FaceSegmentation/SphericalConv/models/SFCNN_seg.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, xyz, projected, cls_label)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0ml3_feature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupsampling1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml3_feature\u001b[0m\u001b[0;34m)\u001b[0m       \u001b[0;31m#Bx1024x162\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0ml2_feature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml3_feature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml2_feature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;31m#Bx(1024+256)x162\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0ml2_feature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml2_feature\u001b[0m\u001b[0;34m)\u001b[0m            \u001b[0;31m#Bx256x162\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml2_feature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: All input tensors must be on the same device. Received cpu and cuda:0"
     ]
    }
   ],
   "source": [
    "model(xyz, projected, cls_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 16]) torch.Size([2, 16, 642])\n",
      "torch.Size([2, 32]) torch.Size([2, 32, 162])\n",
      "torch.Size([2, 64]) torch.Size([2, 64, 42])\n",
      "torch.Size([2, 128]) torch.Size([2, 128, 42])\n",
      "torch.Size([2, 480])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [24, 16, 6, 642]              48\n",
      "       BatchNorm2d-2           [24, 16, 6, 642]              32\n",
      "            Conv2d-3           [24, 16, 6, 642]             272\n",
      "       BatchNorm2d-4           [24, 16, 6, 642]              32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rmclab102/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't multiply sequence by non-int of type 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-8424f8b963bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorchsummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSFs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m642\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torchsummary/torchsummary.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[1;32m     91\u001b[0m         )\n\u001b[1;32m     92\u001b[0m         \u001b[0mtotal_params\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"nb_params\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtotal_output\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"output_shape\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"trainable\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"trainable\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mprod\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mprod\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   3050\u001b[0m     \"\"\"\n\u001b[1;32m   3051\u001b[0m     return _wrapreduction(a, np.multiply, 'prod', axis, dtype, out,\n\u001b[0;32m-> 3052\u001b[0;31m                           keepdims=keepdims, initial=initial, where=where)\n\u001b[0m\u001b[1;32m   3053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't multiply sequence by non-int of type 'list'"
     ]
    }
   ],
   "source": [
    "torchsummary.summary(get_model(16, SFs).cuda(), input_size=(1, 642), batch_size=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# from model_utils import EncodingLayer, SphericalMaxPooling\n",
    "\n",
    "def makeInputData(input_feature, SF):\n",
    "    #feature에서 근점 점 6개 인덱스 뽑아서 MLP 입력 블럭으로 만들어놔\n",
    "    #output : B x N x 6 x 2C (기준 점x6 로 늘려서 근접 점이랑 붙이삼)\n",
    "    '''\n",
    "    input : B x N x C\n",
    "    SF : N x (xyz + p1~p6)\n",
    "\n",
    "    input*6 + p1~p6 (concat) => output\n",
    "\n",
    "    output : B x N x 6 x 2C\n",
    "    '''\n",
    "    #임시로 해놓음\n",
    "    # input_feature = input_feature.numpy()\n",
    "    input_feature = torch.Tensor(input_feature)\n",
    "    # print(input_feature.shape)\n",
    "    B, N, C = input_feature.shape\n",
    "    vertices, near_idx = SF         #near_idx : Nx6\n",
    "    # features = np.reshape(input_feature, (B, N, 1, C))\n",
    "    # input_feature = input_feature.permute(0, 2, 1)\n",
    "    features = input_feature.view(B, N, 1, C)\n",
    "    # features = np.repeat(features, 6, axis=2)   #BxNx6xC\n",
    "    features = features.repeat(1, 1, 6, 1)    #BxNx6xC\n",
    "\n",
    "    # outofidx_6 = np.zeros((B, N, C)) - 1\n",
    "    outofidx_6 = torch.zeros((B, N, C)) - 1\n",
    "    # input_feature = np.concatenate((input_feature, outofidx_6), axis=1) #Bx(N+1)xC\n",
    "\n",
    "    input_feature =  torch.cat((input_feature, outofidx_6), 1)    #Bx(N+1)xC\n",
    "\n",
    "    near_features = input_feature[:, near_idx, :]   #BxNx6xC\n",
    "\n",
    "    # feature_block = np.concatenate((features, near_features), axis=-1)  #BxNx6x2C\n",
    "    feature_block = torch.cat((features, near_features), 3)  #BxNx6x2C\n",
    "\n",
    "    # feature_block = torch.Tensor(feature_block)\n",
    "\n",
    "    return feature_block    #BxNx6x2C\n",
    "\n",
    "def SphericalMaxPooling(input, in_SF, out_SF):\n",
    "    '''\n",
    "    input : B x C x N0\n",
    "    SF0 : (xyz, p01~p05 idx) - (N0 x 3), (N0 x 6)\n",
    "    SF1 : (xyz, p10~p15 idx) - (N1 x 3), (N1 x 6)\n",
    "\n",
    "    output : B x N1 x C\n",
    "\n",
    "    for SF1:\n",
    "        for SF2:\n",
    "            SF2-xyz중에 SF1이랑 같은거 찾아서 p01~p06 인덱스 input에서 d 꺼내와서 pooling\n",
    "            그 값 ouput에 추가\n",
    "    '''\n",
    "    B, C, N = input.shape\n",
    "    input = input.permute(0, 2, 1)\n",
    "\n",
    "    in_v, in_ni = in_SF\n",
    "    out_v, out_ni = out_SF\n",
    "\n",
    "    in_nvertices = in_v.shape[0]\n",
    "    out_nvertices = out_v.shape[0]\n",
    "\n",
    "    output = torch.zeros((B, out_nvertices, C))\n",
    "    \n",
    "    for i in range(out_nvertices):\n",
    "        out_xyz = out_v[i]\n",
    "        for j in range(in_nvertices):\n",
    "            if out_xyz.all() == in_v[j].all():\n",
    "                near_idx = in_ni[j]  #Bx6\n",
    "                temp = input[:, near_idx, :]   #Bx6xC\n",
    "                output[:, i, :] = torch.max(temp, 1)[0]     #BxC\n",
    "\n",
    "    input = input.permute(0, 2, 1)\n",
    "\n",
    "    return output   #BxCxN'\n",
    "\n",
    "    # # input : B x N x (xyz + d + p1~p6 + alpha)로 먼저 만드삼\n",
    "    # # alpha - pooling 기준 점인지 아닌지 (0 : x, 1 : o)\n",
    "    # # for i in range(N):\n",
    "    # #   a=0이면 pass\n",
    "    # #   a=1이면 p1~p6 d값 포함 maxpooling 하고 p1~p6 a값 0으로 변경\n",
    "    # # 그리고 a=0인 애들 다 죽이삼\n",
    "    # # output : B x N x (xyz + d)\n",
    "    # 이거 아님\n",
    "\n",
    "class SphericalMaxPooling(nn.Module):\n",
    "    def __init__(self, in_SF, out_SF):\n",
    "        super(SphericalMaxPooling, self).__init__()\n",
    "        self.in_SF = in_SF\n",
    "        self.out_SF = out_SF\n",
    "    '''\n",
    "    input : B x C x N0\n",
    "    SF0 : (xyz, p01~p05 idx) - (N0 x 3), (N0 x 6)\n",
    "    SF1 : (xyz, p10~p15 idx) - (N1 x 3), (N1 x 6)\n",
    "\n",
    "    output : B x N1 x C\n",
    "\n",
    "    for SF1:\n",
    "        for SF2:\n",
    "            SF2-xyz중에 SF1이랑 같은거 찾아서 p01~p06 인덱스 input에서 d 꺼내와서 pooling\n",
    "            그 값 ouput에 추가\n",
    "    '''\n",
    "\n",
    "    def forward(self, input):\n",
    "        B, C, N = input.shape\n",
    "        input = input.permute(0, 2, 1)\n",
    "\n",
    "        in_v, in_ni = self.in_SF\n",
    "        out_v, out_ni = self.out_SF\n",
    "\n",
    "        in_nvertices = in_v.shape[0]\n",
    "        out_nvertices = out_v.shape[0]\n",
    "\n",
    "        output = torch.zeros((B, out_nvertices, C))\n",
    "        \n",
    "        for i in range(out_nvertices):\n",
    "            out_xyz = out_v[i]\n",
    "            for j in range(in_nvertices):\n",
    "                if out_xyz.all() == in_v[j].all():\n",
    "                    near_idx = in_ni[j]  #Bx6\n",
    "                    temp = input[:, near_idx, :]   #Bx6xC\n",
    "                    output[:, i, :] = torch.max(temp, 1)[0]     #BxC\n",
    "\n",
    "        output = output.permute(0, 2, 1)\n",
    "\n",
    "        return output   #BxCxN'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# from models.SFCNN_utils import EncodingLayer, SphericalMaxPooling\n",
    "# from models.SFCNN_utils import EncodingLayer\n",
    "\n",
    "\n",
    "class get_model(nn.Module):\n",
    "    def __init__(self, num_class, SF_list, normal_channel=False):\n",
    "        super(get_model, self).__init__()\n",
    "        in_channel = 3 if normal_channel else 1\n",
    "        self.normal_channel = normal_channel\n",
    "        self.SF1, self.SF2, self.SF3 = SF_list[2], SF_list[1], SF_list[0]\n",
    "\n",
    "        self.layer0 = EncodingLayer(self.SF3, in_channel, [16, 16]) \n",
    "        self.layer1 = EncodingLayer(self.SF3, 16, [32, 32])   \n",
    "        self.layer2 = EncodingLayer(self.SF2, 32, [64, 64])   \n",
    "        self.layer3 = EncodingLayer(self.SF1, 64, [128, 128])   \n",
    "\n",
    "        self.smp1 = SphericalMaxPooling(self.SF3, self.SF2)\n",
    "        self.smp2 = SphericalMaxPooling(self.SF2, self.SF1)\n",
    "\n",
    "        self.fc1 = nn.Linear(480, 512)\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        # self.drop1 = nn.Dropout(0.4)\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        # self.drop2 = nn.Dropout(0.5)\n",
    "        self.fc3 = nn.Linear(128, num_class)\n",
    "\n",
    "    def forward(self, xyz):\n",
    "        B, _, _ = xyz.shape      #Bx1x642\n",
    "        # if self.normal_channel:\n",
    "        #     norm = xyz[:, 3:, :]\n",
    "        #     xyz = xyz[:, :3, :]\n",
    "        # else:\n",
    "        #     norm = None\n",
    "        # print(xyz.shape)\n",
    "\n",
    "        \n",
    "\n",
    "        l0_inner, l0_outer, l0_feature = self.layer0(xyz)       #Bx16x642\n",
    "        # SphericalMaxPooling(l0_feature, self.SF3, self.SF3)\n",
    "        print(l0_inner.shape, l0_feature.shape)\n",
    "\n",
    "        l1_inner, l1_outer, l1_feature = self.layer1(l0_feature)    #Bx32x642\n",
    "        l1_out = self.smp1(l1_feature)     #Bx32x162\n",
    "        print(l1_inner.shape, l1_out.shape)\n",
    "        \n",
    "        l2_inner, l2_outer, l2_feature = self.layer2(l1_out)     #Bx64x162\n",
    "        l2_out = self.smp2(l2_feature)     #Bx64x42\n",
    "        print(l2_inner.shape, l2_out.shape)\n",
    "        \n",
    "        l3_inner, l3_outer, l3_feature = self.layer3(l2_out)     #Bx128x42\n",
    "        print(l3_inner.shape, l3_feature.shape)\n",
    "\n",
    "        # l0_inner = torch.max(l0_inner, 2)[0]\n",
    "        # l0_feature = torch.max(l0_feature, 2)[0]\n",
    "        # l1_inner = torch.max(l1_inner, 2)[0]\n",
    "        # l1_feature = torch.max(l1_feature, 2)[0]\n",
    "        # l2_inner = torch.max(l2_inner, 2)[0]\n",
    "        # l2_feature = torch.max(l2_feature, 2)[0]\n",
    "        # l3_inner = torch.max(l3_inner, 2)[0]\n",
    "        # l3_feature = torch.max(l3_feature, 2)[0]\n",
    "\n",
    "        out_feature = torch.cat((l0_inner, l0_outer, l1_inner, l1_outer, l2_inner, l2_outer, l3_inner, l3_outer), 1)\n",
    "\n",
    "        print(out_feature.shape)\n",
    "        x = out_feature.view(B, -1)\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = F.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        x = F.log_softmax(x, -1)\n",
    "\n",
    "        return x, l3_feature\n",
    "\n",
    "\n",
    "class get_loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(get_loss, self).__init__()\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        total_loss = F.nll_loss(pred, target)\n",
    "\n",
    "        return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchsummary\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# from model_utils import EncodingLayer, SphericalMaxPooling\n",
    "SF3 = np.random.randint(0, 3, (642, 3)), np.random.randint(-1, 642, (642, 6))\n",
    "SF2 = np.random.randint(0, 3, (162, 3)), np.random.randint(-1, 162, (162, 6))\n",
    "SF1 = np.random.randint(0, 3, (42, 3)), np.random.randint(-1, 42, (42, 6))\n",
    "SFs = [SF3, SF2, SF1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncodingLayer(nn.Module):\n",
    "    def __init__(self, SF, in_channel, mlp, residual=False):\n",
    "        super(EncodingLayer, self).__init__()\n",
    "        self.SF = SF\n",
    "        self.mlp_convs = nn.ModuleList()\n",
    "        self.mlp_bns = nn.ModuleList()\n",
    "        last_channel = in_channel*2\n",
    "\n",
    "        for out_channel in mlp:\n",
    "            self.mlp_convs.append(nn.Conv2d(last_channel, out_channel, 1))  #왜 2d로 함?\n",
    "            self.mlp_bns.append(nn.BatchNorm2d(out_channel))\n",
    "            last_channel = out_channel\n",
    "\n",
    "    def forward(self, points):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "            points: input points data, [B, C, N]\n",
    "        Return:\n",
    "            new_xyz: sampled points position data, [B, C', N]\n",
    "        \"\"\"\n",
    "        points = points.permute(0, 2, 1)    #BxNxC\n",
    "\n",
    "        feature_block = makeInputData(points, self.SF)      #BxNx6x2C\n",
    "        new_feature = feature_block.permute(0, 3, 2, 1)    #Bx2Cx6xN\n",
    "\n",
    "        for i, conv in enumerate(self.mlp_convs):\n",
    "            bn = self.mlp_bns[i]\n",
    "            new_feature =  F.relu(bn(conv(new_feature)))\n",
    "\n",
    "            if i==0:\n",
    "                inner_feature = new_feature\n",
    "        \n",
    "        new_feature = torch.max(new_feature, 2)[0] #[B, C', N] - maxpooling of conv (1 kernel)\n",
    "        inner_feature = torch.max(inner_feature, 2)[0]\n",
    "\n",
    "        inner_feature = torch.max(inner_feature, 2)[0]\n",
    "        out_feature = torch.max(new_feature, 2)[0]\n",
    "        # print(\"ff\")\n",
    "#         new_feature = new_feature.permute(0, 2, 1)\n",
    "#         print(new_feature.shape)\n",
    "\n",
    "        return inner_feature, out_feature, new_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(20, SFs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 16]) torch.Size([20, 16, 642])\n",
      "torch.Size([20, 32]) torch.Size([20, 32, 162])\n",
      "torch.Size([20, 64]) torch.Size([20, 64, 42])\n",
      "torch.Size([20, 128]) torch.Size([20, 128, 42])\n",
      "torch.Size([20, 480])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[-2.9822, -3.0191, -2.9724, -2.9181, -3.0396, -3.0406, -2.9642, -3.0403,\n",
       "          -3.0055, -3.0040, -2.9219, -3.0157, -3.0636, -3.0404, -2.9077, -3.0463,\n",
       "          -2.9752, -3.0383, -2.9233, -3.0189],\n",
       "         [-2.9822, -3.0191, -2.9724, -2.9181, -3.0396, -3.0406, -2.9642, -3.0403,\n",
       "          -3.0055, -3.0040, -2.9219, -3.0157, -3.0636, -3.0404, -2.9077, -3.0463,\n",
       "          -2.9752, -3.0383, -2.9233, -3.0189],\n",
       "         [-2.9822, -3.0191, -2.9724, -2.9181, -3.0396, -3.0406, -2.9642, -3.0403,\n",
       "          -3.0055, -3.0040, -2.9219, -3.0157, -3.0636, -3.0404, -2.9077, -3.0463,\n",
       "          -2.9752, -3.0383, -2.9233, -3.0189],\n",
       "         [-2.9822, -3.0191, -2.9724, -2.9181, -3.0396, -3.0406, -2.9642, -3.0403,\n",
       "          -3.0055, -3.0040, -2.9219, -3.0157, -3.0636, -3.0404, -2.9077, -3.0463,\n",
       "          -2.9752, -3.0383, -2.9233, -3.0189],\n",
       "         [-2.9822, -3.0191, -2.9724, -2.9181, -3.0396, -3.0406, -2.9642, -3.0403,\n",
       "          -3.0055, -3.0040, -2.9219, -3.0157, -3.0636, -3.0404, -2.9077, -3.0463,\n",
       "          -2.9752, -3.0383, -2.9233, -3.0189],\n",
       "         [-2.9822, -3.0191, -2.9724, -2.9181, -3.0396, -3.0406, -2.9642, -3.0403,\n",
       "          -3.0055, -3.0040, -2.9219, -3.0157, -3.0636, -3.0404, -2.9077, -3.0463,\n",
       "          -2.9752, -3.0383, -2.9233, -3.0189],\n",
       "         [-2.9822, -3.0191, -2.9724, -2.9181, -3.0396, -3.0406, -2.9642, -3.0403,\n",
       "          -3.0055, -3.0040, -2.9219, -3.0157, -3.0636, -3.0404, -2.9077, -3.0463,\n",
       "          -2.9752, -3.0383, -2.9233, -3.0189],\n",
       "         [-2.9822, -3.0191, -2.9724, -2.9181, -3.0396, -3.0406, -2.9642, -3.0403,\n",
       "          -3.0055, -3.0040, -2.9219, -3.0157, -3.0636, -3.0404, -2.9077, -3.0463,\n",
       "          -2.9752, -3.0383, -2.9233, -3.0189],\n",
       "         [-2.9822, -3.0191, -2.9724, -2.9181, -3.0396, -3.0406, -2.9642, -3.0403,\n",
       "          -3.0055, -3.0040, -2.9219, -3.0157, -3.0636, -3.0404, -2.9077, -3.0463,\n",
       "          -2.9752, -3.0383, -2.9233, -3.0189],\n",
       "         [-2.9822, -3.0191, -2.9724, -2.9181, -3.0396, -3.0406, -2.9642, -3.0403,\n",
       "          -3.0055, -3.0040, -2.9219, -3.0157, -3.0636, -3.0404, -2.9077, -3.0463,\n",
       "          -2.9752, -3.0383, -2.9233, -3.0189],\n",
       "         [-2.9822, -3.0191, -2.9724, -2.9181, -3.0396, -3.0406, -2.9642, -3.0403,\n",
       "          -3.0055, -3.0040, -2.9219, -3.0157, -3.0636, -3.0404, -2.9077, -3.0463,\n",
       "          -2.9752, -3.0383, -2.9233, -3.0189],\n",
       "         [-2.9822, -3.0191, -2.9724, -2.9181, -3.0396, -3.0406, -2.9642, -3.0403,\n",
       "          -3.0055, -3.0040, -2.9219, -3.0157, -3.0636, -3.0404, -2.9077, -3.0463,\n",
       "          -2.9752, -3.0383, -2.9233, -3.0189],\n",
       "         [-2.9822, -3.0191, -2.9724, -2.9181, -3.0396, -3.0406, -2.9642, -3.0403,\n",
       "          -3.0055, -3.0040, -2.9219, -3.0157, -3.0636, -3.0404, -2.9077, -3.0463,\n",
       "          -2.9752, -3.0383, -2.9233, -3.0189],\n",
       "         [-2.9822, -3.0191, -2.9724, -2.9181, -3.0396, -3.0406, -2.9642, -3.0403,\n",
       "          -3.0055, -3.0040, -2.9219, -3.0157, -3.0636, -3.0404, -2.9077, -3.0463,\n",
       "          -2.9752, -3.0383, -2.9233, -3.0189],\n",
       "         [-2.9822, -3.0191, -2.9724, -2.9181, -3.0396, -3.0406, -2.9642, -3.0403,\n",
       "          -3.0055, -3.0040, -2.9219, -3.0157, -3.0636, -3.0404, -2.9077, -3.0463,\n",
       "          -2.9752, -3.0383, -2.9233, -3.0189],\n",
       "         [-2.9822, -3.0191, -2.9724, -2.9181, -3.0396, -3.0406, -2.9642, -3.0403,\n",
       "          -3.0055, -3.0040, -2.9219, -3.0157, -3.0636, -3.0404, -2.9077, -3.0463,\n",
       "          -2.9752, -3.0383, -2.9233, -3.0189],\n",
       "         [-2.9822, -3.0191, -2.9724, -2.9181, -3.0396, -3.0406, -2.9642, -3.0403,\n",
       "          -3.0055, -3.0040, -2.9219, -3.0157, -3.0636, -3.0404, -2.9077, -3.0463,\n",
       "          -2.9752, -3.0383, -2.9233, -3.0189],\n",
       "         [-2.9822, -3.0191, -2.9724, -2.9181, -3.0396, -3.0406, -2.9642, -3.0403,\n",
       "          -3.0055, -3.0040, -2.9219, -3.0157, -3.0636, -3.0404, -2.9077, -3.0463,\n",
       "          -2.9752, -3.0383, -2.9233, -3.0189],\n",
       "         [-2.9822, -3.0191, -2.9724, -2.9181, -3.0396, -3.0406, -2.9642, -3.0403,\n",
       "          -3.0055, -3.0040, -2.9219, -3.0157, -3.0636, -3.0404, -2.9077, -3.0463,\n",
       "          -2.9752, -3.0383, -2.9233, -3.0189],\n",
       "         [-2.9822, -3.0191, -2.9724, -2.9181, -3.0396, -3.0406, -2.9642, -3.0403,\n",
       "          -3.0055, -3.0040, -2.9219, -3.0157, -3.0636, -3.0404, -2.9077, -3.0463,\n",
       "          -2.9752, -3.0383, -2.9233, -3.0189]], grad_fn=<LogSoftmaxBackward>),\n",
       " tensor([[[0.1422, 0.1422, 0.1422,  ..., 0.1422, 0.1422, 0.1422],\n",
       "          [0.1423, 0.1423, 0.1423,  ..., 0.1423, 0.1423, 0.1423],\n",
       "          [0.1422, 0.1422, 0.1422,  ..., 0.1422, 0.1422, 0.1422],\n",
       "          ...,\n",
       "          [0.0000, 7.0270, 0.0000,  ..., 0.0000, 0.0000, 7.0270],\n",
       "          [0.0000, 7.0280, 0.0000,  ..., 0.0000, 0.0000, 7.0280],\n",
       "          [0.1422, 0.1422, 0.1422,  ..., 0.1422, 0.1422, 0.1422]],\n",
       " \n",
       "         [[0.1422, 0.1422, 0.1422,  ..., 0.1422, 0.1422, 0.1422],\n",
       "          [0.1423, 0.1423, 0.1423,  ..., 0.1423, 0.1423, 0.1423],\n",
       "          [0.1422, 0.1422, 0.1422,  ..., 0.1422, 0.1422, 0.1422],\n",
       "          ...,\n",
       "          [0.0000, 7.0270, 0.0000,  ..., 0.0000, 0.0000, 7.0270],\n",
       "          [0.0000, 7.0280, 0.0000,  ..., 0.0000, 0.0000, 7.0280],\n",
       "          [0.1422, 0.1422, 0.1422,  ..., 0.1422, 0.1422, 0.1422]],\n",
       " \n",
       "         [[0.1422, 0.1422, 0.1422,  ..., 0.1422, 0.1422, 0.1422],\n",
       "          [0.1423, 0.1423, 0.1423,  ..., 0.1423, 0.1423, 0.1423],\n",
       "          [0.1422, 0.1422, 0.1422,  ..., 0.1422, 0.1422, 0.1422],\n",
       "          ...,\n",
       "          [0.0000, 7.0270, 0.0000,  ..., 0.0000, 0.0000, 7.0270],\n",
       "          [0.0000, 7.0280, 0.0000,  ..., 0.0000, 0.0000, 7.0280],\n",
       "          [0.1422, 0.1422, 0.1422,  ..., 0.1422, 0.1422, 0.1422]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.1422, 0.1422, 0.1422,  ..., 0.1422, 0.1422, 0.1422],\n",
       "          [0.1423, 0.1423, 0.1423,  ..., 0.1423, 0.1423, 0.1423],\n",
       "          [0.1422, 0.1422, 0.1422,  ..., 0.1422, 0.1422, 0.1422],\n",
       "          ...,\n",
       "          [0.0000, 7.0270, 0.0000,  ..., 0.0000, 0.0000, 7.0270],\n",
       "          [0.0000, 7.0280, 0.0000,  ..., 0.0000, 0.0000, 7.0280],\n",
       "          [0.1422, 0.1422, 0.1422,  ..., 0.1422, 0.1422, 0.1422]],\n",
       " \n",
       "         [[0.1422, 0.1422, 0.1422,  ..., 0.1422, 0.1422, 0.1422],\n",
       "          [0.1423, 0.1423, 0.1423,  ..., 0.1423, 0.1423, 0.1423],\n",
       "          [0.1422, 0.1422, 0.1422,  ..., 0.1422, 0.1422, 0.1422],\n",
       "          ...,\n",
       "          [0.0000, 7.0270, 0.0000,  ..., 0.0000, 0.0000, 7.0270],\n",
       "          [0.0000, 7.0280, 0.0000,  ..., 0.0000, 0.0000, 7.0280],\n",
       "          [0.1422, 0.1422, 0.1422,  ..., 0.1422, 0.1422, 0.1422]],\n",
       " \n",
       "         [[0.1422, 0.1422, 0.1422,  ..., 0.1422, 0.1422, 0.1422],\n",
       "          [0.1423, 0.1423, 0.1423,  ..., 0.1423, 0.1423, 0.1423],\n",
       "          [0.1422, 0.1422, 0.1422,  ..., 0.1422, 0.1422, 0.1422],\n",
       "          ...,\n",
       "          [0.0000, 7.0270, 0.0000,  ..., 0.0000, 0.0000, 7.0270],\n",
       "          [0.0000, 7.0280, 0.0000,  ..., 0.0000, 0.0000, 7.0280],\n",
       "          [0.1422, 0.1422, 0.1422,  ..., 0.1422, 0.1422, 0.1422]]],\n",
       "        grad_fn=<MaxBackward0>))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.zeros(20, 1, 642)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def readIcosahedron(file_path, n_vertices):       #정리해놓은 Icosahedron 파일 읽어서 SF return\n",
    "    vertices = np.zeros((n_vertices, 3))\n",
    "    near_idx = np.zeros((n_vertices, 6)) - 1\n",
    "\n",
    "    cnt_v = 0\n",
    "    cnt_n = 0\n",
    "\n",
    "    with open(file_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            temp = line.split()\n",
    "\n",
    "            if temp[0] == 'v':\n",
    "                vertices[cnt_v, 0] = temp[1]\n",
    "                vertices[cnt_v, 1] = temp[2]\n",
    "                vertices[cnt_v, 2] = temp[3]\n",
    "                cnt_v += 1\n",
    "\n",
    "            if temp[0] == 'np':\n",
    "                near_idx[cnt_n, 0] = temp[1]\n",
    "                near_idx[cnt_n, 1] = temp[2]\n",
    "                near_idx[cnt_n, 2] = temp[3]\n",
    "                near_idx[cnt_n, 3] = temp[4]\n",
    "                near_idx[cnt_n, 4] = temp[5]\n",
    "                if len(temp)>=7:\n",
    "                    near_idx[cnt_n, 5] = temp[6]\n",
    "\n",
    "                cnt_n += 1\n",
    "\n",
    "    return vertices, near_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SF1 = readIcosahedron('./data_utils/SF1.txt', 42)\n",
    "SF2 = readIcosahedron('./data_utils/SF2.txt', 162)\n",
    "SF3 = readIcosahedron('./data_utils/SF3.txt', 642)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_v, in_ni = SF2\n",
    "out_v, out_ni = SF1\n",
    "\n",
    "in_nvertices = in_v.shape[0]\n",
    "out_nvertices = out_v.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_nvertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "1 1\n",
      "2 2\n",
      "3 3\n",
      "4 4\n",
      "5 5\n",
      "6 6\n",
      "7 7\n",
      "8 8\n",
      "9 9\n",
      "10 10\n",
      "11 11\n",
      "12 12\n",
      "13 13\n",
      "14 14\n",
      "15 15\n",
      "16 16\n",
      "17 17\n",
      "18 18\n",
      "19 19\n",
      "20 20\n",
      "21 21\n",
      "22 22\n",
      "23 23\n",
      "24 24\n",
      "25 25\n",
      "26 26\n",
      "27 27\n",
      "28 28\n",
      "29 29\n",
      "30 30\n",
      "31 31\n",
      "32 32\n",
      "33 33\n",
      "34 34\n",
      "35 35\n",
      "36 36\n",
      "37 37\n",
      "38 38\n",
      "39 39\n",
      "40 40\n",
      "41 41\n"
     ]
    }
   ],
   "source": [
    "with open('./data_utils/SF3toSF2_idxs.txt', 'w') as f:\n",
    "    for i, out_xyz in enumerate(out_v):\n",
    "        for j, in_xyz in enumerate(in_v):\n",
    "            if out_xyz[0] == in_xyz[0] and out_xyz[1] == in_xyz[1] and out_xyz[2] == in_xyz[2]:\n",
    "#                 f.write('%d\\n' % j)\n",
    "                print(i, j)\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(out_path, 'w') as f:\n",
    "                for v in vertices:\n",
    "                    f.write('v')\n",
    "                    for p in v:\n",
    "                        f.write(' %f' % p)\n",
    "                    f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cvtIcosahedron(in_path, out_path):      #Icosahedron .obj 읽어서 nearest point 6개 찾아서 파일로 저장\n",
    "    textured_mesh = o3d.io.read_triangle_mesh(in_path)\n",
    "    vertices = np.asarray(textured_mesh.vertices)\n",
    "    triangle = np.asarray(textured_mesh.triangles)\n",
    "\n",
    "    edge = [[] for i in range(len(vertices))]\n",
    "\n",
    "    for t in triangle:\n",
    "        for idx in t:\n",
    "            for i in t:\n",
    "                if idx!=i and i not in edge[idx]:\n",
    "                    edge[idx].append(i)\n",
    "\n",
    "    with open(out_path, 'w') as f:\n",
    "        for v in vertices:\n",
    "            f.write('v')\n",
    "            for p in v:\n",
    "                f.write(' %f' % p)\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "        for t in triangle:\n",
    "            f.write('f')\n",
    "            for idx in t:\n",
    "                f.write(' %d' % idx)\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "        for nnp in edge:\n",
    "            f.write('np')\n",
    "            for p in nnp:\n",
    "                f.write(' %d' % int(p))\n",
    "            f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
